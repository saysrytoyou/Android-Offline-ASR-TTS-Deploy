package com.example.myaidemo

import android.Manifest
import android.annotation.SuppressLint
import android.content.pm.PackageManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.AudioTrack
import android.media.MediaRecorder
import android.os.Bundle
import android.util.Log
import android.view.MotionEvent
import android.widget.Button
import android.widget.EditText
import android.widget.TextView
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import com.k2fsa.sherpa.onnx.*
import java.util.concurrent.LinkedBlockingQueue
import kotlin.concurrent.thread

class MainActivity : AppCompatActivity() {

    private lateinit var tvResult: TextView
    private lateinit var etInput: EditText
    private lateinit var btnTTS: Button
    private lateinit var btnASR: Button

    // --- AI å¼•æ“å®ä¾‹å®šä¹‰ ---
    private var ttsEngine: OfflineTts? = null
    private var asrRecognizer: OnlineRecognizer? = null
    private var asrStream: OnlineStream? = null
    private var punctEngine: OfflinePunctuation? = null

    @Volatile
    private var isRecording = false
    private var audioRecord: AudioRecord? = null
    private var accumulatedAsrText = ""

    @SuppressLint("ClickableViewAccessibility")
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        tvResult = findViewById(R.id.tvResult)
        etInput = findViewById(R.id.etInput)
        btnTTS = findViewById(R.id.btnTTS)
        btnASR = findViewById(R.id.btnASR)

        checkPermission()

        // åå°å¼‚æ­¥åŠ è½½æ‰€æœ‰ AI æ¨¡å‹ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        thread {
            initTTS()
            initStreamingASR()
            initPunctuation()
            runOnUiThread {
                Toast.makeText(this, "AI å¼•æ“åˆå§‹åŒ–å®Œæ¯•", Toast.LENGTH_SHORT).show()
            }
        }

        btnTTS.setOnClickListener {
            val text = etInput.text.toString().ifEmpty {
                "ä½ å¥½ï¼Œæ¬¢è¿ä½“éªŒç«¯ä¾§å¤§æ¨¡å‹ã€‚è¿™æ˜¯ä¸€æ®µç”¨æ¥æµ‹è¯•æé™è¿è´¯åº¦çš„é•¿éš¾å¥æ–‡æœ¬ï¼Œè¯·ä»”ç»†å¬ä¸€ä¸‹åœ¨å¤šæ ¸åŠ é€Ÿå’Œç«¯ç‚¹é™éŸ³åˆ‡é™¤çš„åŠ æŒä¸‹ï¼Œå®ƒæ˜¯ä¸æ˜¯åƒçœŸäººè¯´è¯ä¸€æ ·ä¸æ»‘è‡ªç„¶å‘¢ï¼Ÿæµ‹è¯•ç»“æŸã€‚"
            }
            tvResult.text = "æ­£åœ¨æµå¼åˆæˆä¸æ’­æ”¾..."
            startStreamingTTS(text)
        }

        btnASR.setOnTouchListener { _, event ->
            when (event.action) {
                MotionEvent.ACTION_DOWN -> {
                    btnASR.text = "æ­£åœ¨è¯†åˆ«..."
                    startRecording()
                    true
                }
                MotionEvent.ACTION_UP -> {
                    btnASR.text = "æ­£åœ¨æ’ç‰ˆ..."
                    stopRecording()
                    true
                }
                else -> false
            }
        }
    }

    // --- 1. åˆå§‹åŒ– TTSå¼•æ“ (å¼€å¯å¤šæ ¸å¹¶è¡ŒåŠ é€Ÿ) ---
    private fun initTTS() {
        try {
            val config = OfflineTtsConfig(
                model = OfflineTtsModelConfig(
                    vits = OfflineTtsVitsModelConfig(
                        model = "tts/vits-bilingual.onnx",
                        tokens = "tts/tokens.txt",
                        lexicon = "tts/lexicon.txt",
                        dictDir = "tts"
                    ),
                    // åˆ†é… 4 ä¸ª CPU çº¿ç¨‹è¿›è¡Œæ¨ç†ï¼Œæå¤§åœ°æå‡ç”Ÿæˆé€Ÿåº¦
                    numThreads = 4,
                    debug = false
                )
            )
            ttsEngine = OfflineTts(assets, config)
        } catch (e: Exception) {
            Log.e("MyAiDemo", "TTS Init Error: ${e.message}")
        }
    }

    // --- 2. åˆå§‹åŒ–æ ‡ç‚¹æ¨¡å‹ (ç”¨äºæ¢å¤æ ‡ç‚¹ä¸å¤§å°å†™) ---
    private fun initPunctuation() {
        try {
            val config = OfflinePunctuationConfig(
                model = OfflinePunctuationModelConfig(ctTransformer = "punct/model.onnx")
            )
            punctEngine = OfflinePunctuation(assets, config)
        } catch (e: Exception) {}
    }

    // --- 3. åˆå§‹åŒ–æµå¼ ASR (é«˜ç²¾åº¦ Paraformer æ¶æ„) ---
    private fun initStreamingASR() {
        try {
            val config = OnlineRecognizerConfig(
                featConfig = FeatureConfig(sampleRate = 16000, featureDim = 80),
                modelConfig = OnlineModelConfig(
                    paraformer = OnlineParaformerModelConfig(
                        encoder = "asr/encoder.int8.onnx",
                        decoder = "asr/decoder.int8.onnx"
                    ),
                    tokens = "asr/tokens.txt",
                    modelType = "paraformer"
                ),
                enableEndpoint = true, // å¼€å¯ç«¯ç‚¹é™éŸ³æ£€æµ‹
                endpointConfig = EndpointConfig(
                    rule1 = EndpointRule(false, 2.4f, 0.0f),
                    rule2 = EndpointRule(true, 1.2f, 0.0f),
                    rule3 = EndpointRule(false, 0.0f, 20.0f)
                )
            )
            asrRecognizer = OnlineRecognizer(assets, config)
        } catch (e: Exception) {
            Log.e("MyAiDemo", "ASR Init Error: ${e.message}")
        }
    }

    // --- 4. å®æ—¶æµå¼å½•éŸ³è¯†åˆ« (è¾¹è¯´è¾¹å‡ºå­—) ---
    private fun startRecording() {
        if (isRecording) return
        isRecording = true
        accumulatedAsrText = ""

        asrStream = asrRecognizer?.createStream()

        thread {
            if (ActivityCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) return@thread

            val bufferSize = AudioRecord.getMinBufferSize(16000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT)
            audioRecord = AudioRecord(MediaRecorder.AudioSource.MIC, 16000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT, bufferSize)
            audioRecord?.startRecording()

            val buffer = ShortArray(bufferSize)
            val floatBuffer = FloatArray(bufferSize)

            while (isRecording) {
                val read = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                if (read > 0) {
                    for (i in 0 until read) { floatBuffer[i] = buffer[i] / 32768.0f }

                    val stream = asrStream ?: continue
                    val recognizer = asrRecognizer ?: continue

                    // æŒç»­å°†éŸ³é¢‘ç‰¹å¾å–‚ç»™æ¨¡å‹
                    stream.acceptWaveform(floatBuffer, sampleRate = 16000)

                    while (recognizer.isReady(stream)) {
                        recognizer.decode(stream)
                    }

                    val currentSegment = recognizer.getResult(stream).text
                    val isEndpoint = recognizer.isEndpoint(stream)

                    // å®æ—¶æ›´æ–° UI ä¸Šå±
                    val displayText = accumulatedAsrText + currentSegment
                    if (displayText.isNotEmpty()) {
                        runOnUiThread { tvResult.text = displayText }
                    }

                    // æ£€æµ‹åˆ°æ–­å¥æ—¶ï¼Œå›ºåŒ–å½“å‰æ®µè½
                    if (isEndpoint) {
                        accumulatedAsrText += currentSegment
                        recognizer.reset(stream)
                    }
                }
            }
        }
    }

    // --- 5. å½•éŸ³ç»“æŸ (è§£ç å°¾éŸ³ä¸è°ƒç”¨æ’ç‰ˆ) ---
    private fun stopRecording() {
        isRecording = false
        try { audioRecord?.stop(); audioRecord?.release() } catch (e: Exception) {}
        audioRecord = null

        thread {
            val stream = asrStream ?: return@thread
            val recognizer = asrRecognizer ?: return@thread

            // å‹å…¥ç©ºéŸ³é¢‘å‘ŠçŸ¥è¯†åˆ«æµç»“æŸ
            stream.acceptWaveform(FloatArray(0), 16000)
            while (recognizer.isReady(stream)) {
                recognizer.decode(stream)
            }

            val finalSegment = recognizer.getResult(stream).text
            val fullRawText = accumulatedAsrText + finalSegment

            if (fullRawText.isNotEmpty()) {
                val finalPrettyText = smartProcessText(fullRawText)

                runOnUiThread {
                    tvResult.text = finalPrettyText
                    etInput.setText(finalPrettyText)
                    btnASR.text = "ASR: æŒ‰ä½è¯´è¯"
                }
            } else {
                runOnUiThread { btnASR.text = "ASR: æŒ‰ä½è¯´è¯" }
            }
            stream.release()
        }
    }

    // --- 6. æ™ºèƒ½æ–‡æœ¬æ’ç‰ˆä¸æ¸…ç† (æ ‡ç‚¹å»é‡ä¸ä¿®å¤) ---
    private fun smartProcessText(rawText: String): String {
        if (rawText.isBlank()) return ""
        var cleanText = rawText.replace(Regex("[ï¼Œã€‚ï¼Ÿï¼,.?!:;]"), " ").trim()
        cleanText = cleanText.lowercase()
        var processed = punctEngine?.addPunctuation(cleanText) ?: cleanText

        processed = processed
            .replace(Regex("([ï¼Œã€‚ï¼Ÿï¼,.?!])\\1+"), "$1")
            .replace("ã€‚ï¼Ÿ", "ï¼Ÿ").replace("ï¼Ÿã€‚", "ï¼Ÿ").replace("ï¼ã€‚", "ï¼").replace("ï¼Œã€‚", "ã€‚")
            .trimStart { it in "ï¼Œã€‚ï¼Ÿï¼,.?!" }

        return processed
    }

    // --- 7. ç»ˆææ€§èƒ½ç‰ˆï¼šæµå¼æ— ç¼ TTS (åŒçº¿ç¨‹ + VADè£å‰ª + é¦–å¥ç§’å‡º) ---
    private fun startStreamingTTS(text: String) {
        thread {
            ttsEngine?.let { tts ->
                var cleanText = text.replace(Regex("<.*?>"), "").uppercase()

                if (!cleanText.matches(Regex(".*[ã€‚ï¼Ÿï¼.?!].*"))) {
                    cleanText += "ã€‚"
                }

                // åŠ¨æ€åˆ†å¥ç­–ç•¥ï¼šä¼˜å…ˆåœ¨å¥å°¾åˆ‡åˆ†ï¼›è‹¥é•¿éš¾å¥(>25å­—)åˆ™æŒ‰é€—å·åˆ‡åˆ†ï¼Œé˜²å†…å­˜é˜»å¡
                val majorChunks = cleanText.split(Regex("(?<=[ã€‚ï¼Ÿï¼.?!])")).filter { it.isNotBlank() }
                val finalChunks = mutableListOf<String>()
                for (chunk in majorChunks) {
                    if (chunk.length > 25) {
                        finalChunks.addAll(chunk.split(Regex("(?<=[ï¼Œã€,])")).filter { it.isNotBlank() })
                    } else {
                        finalChunks.add(chunk)
                    }
                }

                // çº¿ç¨‹å®‰å…¨çš„éŸ³é¢‘ç¼“å†²é˜Ÿåˆ—
                val audioQueue = LinkedBlockingQueue<FloatArray>()
                val poisonPill = FloatArray(0)
                var currentSampleRate = 22050

                // ğŸ‘‰ çº¿ç¨‹ 1 (ç”Ÿäº§è€…)ï¼šç”ŸæˆéŸ³é¢‘å¹¶åŠ¨æ€åˆ‡é™¤ç«¯ç‚¹é™éŸ³ (VAD Trimming)
                thread {
                    for (chunk in finalChunks) {
                        if (chunk.trim { it in "ï¼Œã€‚ï¼Ÿï¼,.?!ã€ " }.isEmpty()) continue

                        val audio = tts.generate(chunk, sid = 0, speed = 0.85f)
                        if (audio.samples.isNotEmpty()) {
                            currentSampleRate = audio.sampleRate
                            val samples = audio.samples

                            // åŠ¨æ€æŠ¹é™¤æ¨¡å‹é»˜è®¤ç”Ÿæˆçš„æ‹¼æ¥é™éŸ³ (é˜ˆå€¼ 0.005f)
                            var startIdx = 0
                            var endIdx = samples.size - 1
                            val threshold = 0.005f

                            while (startIdx < samples.size && Math.abs(samples[startIdx]) < threshold) startIdx++
                            while (endIdx > startIdx && Math.abs(samples[endIdx]) < threshold) endIdx--

                            if (startIdx <= endIdx) {
                                audioQueue.put(samples.copyOfRange(startIdx, endIdx + 1))
                            }
                        }
                    }
                    audioQueue.put(poisonPill)
                }

                var track: AudioTrack? = null

                try {
                    // ğŸ‘‰ çº¿ç¨‹ 2 (æ¶ˆè´¹è€…)ï¼šæ‹¿åˆ°ç¬¬ä¸€å¥ç«‹åˆ»å¼€æ’­ï¼Œåç»­æ— ç¼è¿½èµ¶
                    val firstAudio = audioQueue.take()
                    if (firstAudio.isNotEmpty()) {
                        val minBufferSize = AudioTrack.getMinBufferSize(
                            currentSampleRate,
                            AudioFormat.CHANNEL_OUT_MONO,
                            AudioFormat.ENCODING_PCM_FLOAT
                        )
                        // å°†ç¼“å†²åŒºæ”¾å¤§ 4 å€ï¼Œæ„å»ºæŠ—ç®—åŠ›æ³¢åŠ¨çš„è“„æ°´æ± 
                        track = AudioTrack(
                            android.media.AudioManager.STREAM_MUSIC,
                            currentSampleRate,
                            AudioFormat.CHANNEL_OUT_MONO,
                            AudioFormat.ENCODING_PCM_FLOAT,
                            minBufferSize * 4,
                            AudioTrack.MODE_STREAM
                        )
                        track.play()

                        track.write(firstAudio, 0, firstAudio.size, AudioTrack.WRITE_BLOCKING)

                        // å¾ªç¯æ¥ç®¡é˜Ÿåˆ—
                        while (true) {
                            val samples = audioQueue.take()
                            if (samples.isEmpty()) break
                            track.write(samples, 0, samples.size, AudioTrack.WRITE_BLOCKING)
                        }
                        Thread.sleep(800)
                    }
                } catch (e: Exception) {
                    Log.e("MyAiDemo", "TTS Playback Error: ${e.message}")
                } finally {
                    track?.stop()
                    track?.release()
                }

                runOnUiThread {
                    tvResult.text = "æ’­æ”¾å®Œæ¯•"
                }
            }
        }
    }

    // --- 8. éº¦å…‹é£åŠ¨æ€æƒé™æ£€æŸ¥ ---
    private fun checkPermission() {
        if (ActivityCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), 1)
        }
    }
}